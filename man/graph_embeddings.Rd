% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/graph_embeddings.R
\name{graph_embeddings}
\alias{graph_embeddings}
\title{Calculate Graph Embeddings}
\usage{
graph_embeddings(
  landmarks,
  edge_matrix,
  num_convolutions = 2,
  dist_method = "cosine"
)
}
\arguments{
\item{landmarks}{A (num_landmark x num_dimension x num_individuals) array (or tensor) containing
superimposed landmark coordinates}

\item{edge_matrix}{A matrix defining the edges for the graph, either defined by the
user or by the \code{calc_edge_matrix} function.}

\item{num_convolutions}{An integer defining the number of convolutions to be used
to calculate the final embedding. num_convolutions can not be more than the diameter
of the graph.}

\item{dist_method}{The method to be used to define the final similarity matrix (
"cosine", "euclid" or "chebyshev").}
}
\value{
\code{similarity_vector} - similarity vectors for each individual

\code{landmark_embeddings} - an array of the embedded landmarks
}
\description{
The present function can be used to calculate embeddings for each landmark configuration,
producing a final output of each embedded individual, as well as the similarity matrix.
}
\section{Details}{

This function is the central component of the graphGMM library, used to project landmark
configurations into a new embedded feature space, and calculate the similarity matrix
that represents the structural properties of the entire configuration.

The embedding component of this function aims to project landmarks into a new 2 or 3 dimensional
feature space, so that nodes in the graph that are structurally similiar are embedded closer
together. In this sense, similarity found in the new embedded landmark configuration,
should approximate the similarity observed in biological or geometric structure.

For embedding, the present algorithm uses graph theory and the concept of a graph convolution,
typically used in graph based representation learning. Each landmark configuration
is thus represented as an undirected graph \eqn{G}, where every landmark is a node
\eqn{LM_{v} \in V}, and is connected to neighbour \eqn{LM_{u}} via an edge. \eqn{G}
can thus be represented as an adjacency matrix \eqn{A \in \mathbb{R}^{p \times p}},
with a feature matrix \eqn{X \in \mathbb{R}^{p \times k}} of procrustes landmark
coordinates, where \eqn{p} is the number of landmarks, and \eqn{k} is the number of dimensions.

The embedding process thus consists in a message passing and neighbourhood aggregation
scheme, whereby each landmark is transformed to be a function of itself and its neighbours.
For this purpose, the convolution formula proposed by Kipf and Welling (2017) was adapted and
implemented, using a standardised version of the adjacency matrix transformed with landmark
centrality degrees, as well as self loops, to perform a single message-passing convolution on the graph.

To ensure that the embedding includes information from landmarks further away across the graph,
then the depth of the embedding can be increased using a higher number of convolutions.
Nevertheless, the present function will not compute if the number of convolutions
is higher than the natural diameter of the graph.

Once the landmarks have been embedded, the transformed configuration is converted
into a similarity matrix, calculating the structural similarity of each landmark in
relation to all landmarks within the configuration. For this purpose, three different
similarity matrices can be calculated (Cosine, Euclidean and Chebyshev),
however optimal results (and the most recommendable
approach), is obtained using the cosine similarity function.
}

\section{Bibliography}{

Kipf, T.N.; Welling, M. (2017) Semi-supervised classification with graph
convolutional networks. International Conference on Learning Representations. arXiv:
1609.02907v4

Leskovec, J. (2019) Graph Node Embedding Algorithms, Stanford University CS224W:
Machine Learning with Graphs.

Wang, Y.; Sun, Y.; Lui, Z.; Sarma, S.E.; Bronstein, M.M.; Solomon, J.M. (2019)
Dynamic Graph CNN for Learning on Point Clouds, ACM Transaction on Graphics,
1(1):1-13, arXiv: 1801.07829v2

Bronstein, M.M.; Bruna, J.; Cohen, T.; Velickovic, P. (2021) Geometric Deep Learning
Grids, Groups, Graphs, Geodesics, and Gauges, arXiv: 2104.13478v2

Courtenay, L.A.; Aramendi, J.; Gonz√°lez-Aguilera, D. (In Prep) A Graph
Based Geometric Morphometric approach to the analysis of primate radii:
A new mathematical model for the processing of landmark data.
}

\examples{
library(shapes)
library(GraphGMM)

# load data
data(apes)

# Generalized Procrustes Fit
GPAshape <- GPA(apes$x)

# calculate central configuration
central_config <- calc_central_morph(GPAshape$rotated)

# compute graph edges
edges <- triangulate2d(central_config)

# extract edge list
edge_list <- as_edge_list(edges)

# create graph embeddings
graph_object <- graph_embeddings(GPAshape$rotated, edge_list,
                                 num_convolutions = 2)

}
\author{
Lloyd A. Courtenay
}
